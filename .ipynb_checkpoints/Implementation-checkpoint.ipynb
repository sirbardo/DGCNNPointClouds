{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "Float = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "Long = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Int = torch.cuda.IntTensor if use_cuda else torch.IntTensor\n",
    "Double = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "scale_factor = 1\n",
    "\n",
    "with open ('head_american.txt', 'r') as file:\n",
    "    \n",
    "    for line in file.readlines():\n",
    "        line = line.split()\n",
    "        x_train += [np.array([float(line[0])*scale_factor, \n",
    "                              float(line[1])*scale_factor, \n",
    "                              float(line[2])*scale_factor])]\n",
    "        y_train += [np.array(int(line[3]))]\n",
    "        \n",
    "with open ('head_korean.txt', 'r') as file:\n",
    "    \n",
    "    for line in file.readlines():\n",
    "        line = line.split()\n",
    "        x_test += [np.array([float(line[0])*scale_factor, \n",
    "                              float(line[1])*scale_factor, \n",
    "                              float(line[2])*scale_factor])]\n",
    "        y_test += [np.array(int(line[3]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(point_cloud):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    point_cloud: tensor (batch_size, num_points, num_dims)\n",
    "    Returns:\n",
    "    pairwise distance: (batch_size, num_points, num_points)\n",
    "    \"\"\"\n",
    "    batch_size = point_cloud.size()[0]\n",
    "    point_cloud = torch.squeeze(point_cloud)\n",
    "    if batch_size==1:\n",
    "        point_cloud = point_cloud.unsqueeze(0)\n",
    "    point_cloud_transpose = point_cloud.permute(0, 2, 1)\n",
    "    point_cloud_inner = -2*torch.bmm(point_cloud, point_cloud_transpose)\n",
    "    point_cloud_square = (point_cloud**2).sum(dim=-1, keepdim=True)\n",
    "    point_cloud_square_transpose = point_cloud_square.permute(0, 2, 1)\n",
    "    return point_cloud_square + point_cloud_inner + point_cloud_square_transpose\n",
    "\n",
    "def knn(dist_mat, k=20):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    pairwise distance: (batch_size, num_points, num_points)\n",
    "    k: int\n",
    "    Returns:\n",
    "    nearest neighbors: (batch_size, num_points, k)\n",
    "    \"\"\"\n",
    "    _, nn_idx = torch.topk(dist_mat, k=k, largest=False, sorted=False)\n",
    "    return nn_idx.cuda()\n",
    "\n",
    "def get_edge_feature(point_cloud, nn_idx, k=20):\n",
    "\n",
    "    batch_size = point_cloud.size()[0]\n",
    "    point_cloud = torch.squeeze(point_cloud)\n",
    "    \n",
    "    if batch_size==1:\n",
    "        point_cloud = point_cloud.unsqueeze(0)\n",
    "        \n",
    "    _,num_points,num_dims = point_cloud.size()\n",
    "\n",
    "    idx_ = torch.arange(batch_size) * num_points\n",
    "    idx_ = torch.autograd.Variable(idx_.view(batch_size, 1, 1).long())\n",
    "\n",
    "    idx_ = idx_.cuda()\n",
    "    \n",
    "    # print(nn_idx, batch_size, nn_idx+idx_)\n",
    "\n",
    "    point_cloud_flat = point_cloud.contiguous().view(-1, num_dims).cuda()\n",
    "    # point_cloud_nbrs = torch.gather(point_cloud_flat, dim=0, index=nn_idx+idx_)\n",
    "    point_cloud_nbrs = torch.index_select(point_cloud_flat, dim=0, index=(nn_idx+idx_).view(-1, 1).squeeze().cuda())\n",
    "    point_cloud_nbrs = point_cloud_nbrs.view(batch_size,num_points,k,-1)\n",
    "\n",
    "    # print(point_cloud_nbrs)\n",
    "\n",
    "\n",
    "    point_cloud_central = point_cloud.unsqueeze(-2)\n",
    "    point_cloud_central = point_cloud_central.expand(-1,-1,k,-1)\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "\n",
    "    edge_feature = torch.cat((point_cloud_central, point_cloud_nbrs-point_cloud_central), dim=-1).cuda()\n",
    "    return edge_feature\n",
    "\n",
    "def convert_label_to_one_hot(labels):\n",
    "  label_one_hot = np.zeros((labels.shape[0], np.max(labels)+1))\n",
    "  for idx in range(labels.shape[0]):\n",
    "    label_one_hot[idx, labels[idx]] = 1\n",
    "  return label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_transform_net(nn.Module):\n",
    "    \"\"\"docstring for input_transform_net\"\"\"\n",
    "    def __init__(self, K=3):\n",
    "        super(input_transform_net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(6, 64, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv2d(128, 1024, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, K*K)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.const = torch.Tensor(torch.from_numpy(np.eye(K).flatten()).float()).cuda()\n",
    "        self.K = K\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, edge_feat):\n",
    "\n",
    "        batch_size, num_points = edge_feat.size()[0], edge_feat.size()[2]\n",
    "\n",
    "        self.mp1 = nn.MaxPool2d((num_points, 1), stride=2)\n",
    "\n",
    "        x = self.bn1(F.relu(self.conv1(edge_feat)))\n",
    "        x = self.bn2(F.relu(self.conv2(x)))\n",
    "        x,_ = torch.max(x, dim=-1, keepdim=True)\n",
    "\n",
    "        x = self.bn3(F.relu(self.conv3(x)))\n",
    "        x = self.mp1(x)\n",
    "\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        x = self.bn4(F.relu(self.fc1(x)))\n",
    "        x = self.bn5(F.relu(self.fc2(x)))\n",
    "\n",
    "        x = self.fc3(x) + self.const\n",
    "\n",
    "        x = x.view(batch_size, self.K, self.K)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.autograd as grad\n",
    "import torch.optim as optim\n",
    "class part_seg_net(nn.Module):\n",
    "    \"\"\"docstring for part_seg_net\"\"\"\n",
    "    def __init__(self, part_num, k=100, cat_num=16):\n",
    "        super(part_seg_net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(6, 64, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        self.conv4 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        self.conv5 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        self.conv6 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        self.conv7 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        self.conv8 = nn.Conv2d(192, 1024, kernel_size=1)\n",
    "        self.conv9 = nn.Conv2d(cat_num, 128, kernel_size=1)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(2752, 256, kernel_size=1)\n",
    "        self.conv11 = nn.Conv2d(256, 256, kernel_size=1)\n",
    "        self.conv12 = nn.Conv2d(256, 128, kernel_size=1)\n",
    "        self.conv13 = nn.Conv2d(128, part_num, kernel_size=1)\n",
    "\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.bn7 = nn.BatchNorm2d(64)\n",
    "        self.bn8 = nn.BatchNorm2d(1024)\n",
    "        self.bn9 = nn.BatchNorm2d(128)\n",
    "        self.bn10 = nn.BatchNorm2d(256)\n",
    "        self.bn11 = nn.BatchNorm2d(256)\n",
    "        self.bn12 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "        self.input_transform = input_transform_net().cuda() if torch.cuda.is_available() else input_transform_net()\n",
    "\n",
    "        self.k = k\n",
    "        self.part_num = part_num\n",
    "        self.cat_num = cat_num\n",
    "\n",
    "    def forward(self, point_cloud, object_label):\n",
    "\n",
    "        batch_size, num_point,_ = point_cloud.size()\n",
    "        input_img = point_cloud.unsqueeze(-1)\n",
    "\n",
    "        self.mp1 = nn.MaxPool2d((num_point, 1), stride=2)\n",
    "\n",
    "        dist_mat = pairwise_distance(point_cloud)\n",
    "        nn_idx = knn(dist_mat, k=self.k)\n",
    "        edge_feat = get_edge_feature(input_img, nn_idx=nn_idx, k=self.k)\n",
    "        edge_feat = edge_feat.permute(0,3,1,2)\n",
    "        # point_cloud = point_cloud.permute(0,2,1)\n",
    "\n",
    "        transform_mat = self.input_transform(edge_feat)\n",
    "\n",
    "        point_cloud_transformed = torch.bmm(point_cloud, transform_mat).cuda()\n",
    "        input_img = point_cloud_transformed.unsqueeze(-1)\n",
    "        \n",
    "        dist_mat = pairwise_distance(point_cloud_transformed)\n",
    "        nn_idx = knn(dist_mat, k=self.k)\n",
    "        edge_feat = get_edge_feature(input_img, nn_idx=nn_idx, k=self.k)\n",
    "        edge_feat = edge_feat.permute(0,3,1,2)\n",
    "\n",
    "\n",
    "        out1 = self.bn1(F.relu(self.conv1(edge_feat)))\n",
    "        out1 = self.bn2(F.relu(self.conv2(out1)))\n",
    "        out_max1,_ = torch.max(out1, dim=-1, keepdim=True)\n",
    "        out_mean1 = torch.mean(out1, dim=-1, keepdim=True)\n",
    "\n",
    "        out3 = self.bn3(F.relu(self.conv3(torch.cat((out_max1, out_mean1), dim=1))))\n",
    "\n",
    "        out = out3.permute(0,2,3,1)\n",
    "        dist_mat = pairwise_distance(out)\n",
    "        nn_idx = knn(dist_mat, k=self.k)\n",
    "        edge_feat = get_edge_feature(out, nn_idx=nn_idx, k=self.k)\n",
    "        edge_feat = edge_feat.permute(0,3,1,2)\n",
    "\n",
    "        out = self.bn4(F.relu(self.conv4(edge_feat)))\n",
    "        out_max2,_ = torch.max(out, dim=-1, keepdim=True)\n",
    "        out_mean2 = torch.mean(out, dim=-1, keepdim=True)\n",
    "\n",
    "        out5 = self.bn5(F.relu(self.conv5(torch.cat((out_max2, out_mean2), dim=1))))\n",
    "\n",
    "        out = out5.permute(0,2,3,1)\n",
    "        dist_mat = pairwise_distance(torch.squeeze(out, dim=-2))\n",
    "        nn_idx = knn(dist_mat, k=self.k)\n",
    "        edge_feat = get_edge_feature(out, nn_idx=nn_idx, k=self.k)\n",
    "        edge_feat = edge_feat.permute(0,3,1,2)\n",
    "\n",
    "        out = self.bn6(F.relu(self.conv6(edge_feat)))\n",
    "        out_max3,_ = torch.max(out, dim=-1, keepdim=True)\n",
    "        out_mean3 = torch.mean(out, dim=-1, keepdim=True)\n",
    "        out7 = self.bn7(F.relu(self.conv7(torch.cat((out_max3, out_mean3), dim=1))))\n",
    "\n",
    "        out8 = self.bn8(F.relu(self.conv8(torch.cat((out3, out5, out7), dim=1))))\n",
    "\n",
    "        out_max = self.mp1(out8)\n",
    "\n",
    "        one_hot_label_expand = object_label.view(batch_size, self.cat_num, 1, 1)\n",
    "        one_hot_label_expand = self.bn9(F.relu(self.conv9(one_hot_label_expand)))\n",
    "        out_max = torch.cat((out_max, one_hot_label_expand), dim=1)\n",
    "        out_max = out_max.expand(-1,-1,num_point,-1)\n",
    "\n",
    "        concat = torch.cat((out_max, out_max1, out_mean1,\n",
    "                            out3, out_max2, out_mean2,\n",
    "                            out5, out_max3, out_mean3,\n",
    "                            out7, out8), dim=1)\n",
    "\n",
    "        net2 = self.bn10(F.relu(self.conv10(concat)))\n",
    "        net2 = self.dropout(net2)\n",
    "        net2 = self.bn11(F.relu(self.conv11(net2)))\n",
    "        net2 = self.dropout(net2)\n",
    "        net2 = self.bn12(F.relu(self.conv12(net2)))\n",
    "        net2 = self.conv13(net2)\n",
    "\n",
    "        net2 = net2.view(batch_size, self.part_num, num_point, 1)\n",
    "        net2 = F.log_softmax(net2, dim=1)\n",
    "\n",
    "\n",
    "        return net2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = part_seg_net(5, cat_num=1)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "n_batches = 32\n",
    "n_batches_train = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = np.ones((n_batches_train, 100))\n",
    "\"\"\"TODO: Find a less awkward way of dealing with batches. Right now n_batch has to be a divisor of the number of points\"\"\"\n",
    "labels = np.array(y_train)\n",
    "#labels = np.reshape(labels, (n_batches_train, int(labels.shape[1]//n_batches_train)))\n",
    "\n",
    "labels_test = np.array(y_test)\n",
    "#labels_test = np.reshape(labels_test, (n_batches, int(labels_test.shape[1]//n_batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud = np.array(x_train)\n",
    "#point_cloud = np.reshape(point_cloud, (n_batches_train, point_cloud.shape[0]//n_batches_train, 3))\n",
    "\n",
    "point_cloud_test = np.array(x_test)\n",
    "#point_cloud_test = np.reshape(point_cloud_test, (n_batches, point_cloud_test.shape[0]//n_batches, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = [convert_label_to_one_hot(i) for i in labels]\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109527,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109527, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_cloud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point_cloud = torch.Tensor(point_cloud).cuda()\n",
    "#labels = torch.LongTensor(labels).cuda()\n",
    "\n",
    "#point_cloud_test = torch.Tensor(point_cloud_test).cuda()\n",
    "#labels_test = torch.LongTensor(labels_test).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point_cloud = torch.Tensor(np.random.randn(n_batches_train,100,3)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "object_labels_fake = np.zeros((n_batches_train, 1), dtype='int')\n",
    "#object_labels_fake = [convert_label_to_one_hot(i) for i in object_labels_fake]\n",
    "object_labels_fake = torch.Tensor(object_labels_fake).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109527"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 100\n",
    "n_of_points = 100\n",
    "\n",
    "batches = []\n",
    "batches_labels = []\n",
    "\n",
    "for i in range(0, point_cloud.shape[0], mini_batch_size):\n",
    "    \n",
    "    curr_mini_batch = []\n",
    "    curr_mini_batch_labels = []\n",
    "        \n",
    "    for k in (range(mini_batch_size)):\n",
    "        \n",
    "        curr_item = []\n",
    "        curr_item_labels = []\n",
    "        \n",
    "        for j in range(0, n_of_points):\n",
    "            \n",
    "            if i*n_of_points+(k*n_of_points)+j >= point_cloud.shape[0]:\n",
    "                break\n",
    "\n",
    "            curr_item += [point_cloud[i*n_of_points+(k*n_of_points)+j]]\n",
    "            curr_item_labels += [labels[i*n_of_points+(k*n_of_points)+j]]\n",
    "            \n",
    "        if i*n_of_points+(k*n_of_points)+j >= point_cloud.shape[0]:\n",
    "            break\n",
    "\n",
    "        curr_mini_batch += [np.array(curr_item)]\n",
    "        curr_mini_batch_labels += [np.array(curr_item_labels)]\n",
    "        \n",
    "    if (curr_mini_batch == []):\n",
    "        break\n",
    "        \n",
    "    batches += [np.array(curr_mini_batch)]\n",
    "    batches_labels += [np.array(curr_mini_batch_labels)]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [torch.Tensor(i).cuda() for i in batches]\n",
    "batches_labels = [torch.LongTensor(i).cuda() for i in batches_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prova = np.array(prova)\n",
    "#prova = [np.array(i) for i in prova]\n",
    "#prova = np.array(prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_label_fake = torch.zeros(mini_batch_size, 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_label_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef590c180d984e7b858366413838ef8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274628769e5e4fcdb792574055aacee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac9da8324da49aba2c1f558400b3c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (77) : an illegal memory access was encountered at c:\\new-builder_3\\win-wheel\\pytorch\\aten\\src\\thc\\generic/THCTensorMathPointwise.cu:308",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6e46375bcd07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mpart_label_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_to_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpart_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart_label_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-5c5d809698df>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, point_cloud, object_label)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mdist_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint_cloud_transformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mnn_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0medge_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_edge_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0medge_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_feat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b26b32a2a892>\u001b[0m in \u001b[0;36mget_edge_feature\u001b[1;34m(point_cloud, nn_idx, k)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# pdb.set_trace()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0medge_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint_cloud_central\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoint_cloud_nbrs\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpoint_cloud_central\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0medge_feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (77) : an illegal memory access was encountered at c:\\new-builder_3\\win-wheel\\pytorch\\aten\\src\\thc\\generic/THCTensorMathPointwise.cu:308"
     ]
    }
   ],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "\n",
    "total_loss = 0.0\n",
    "total_seg_acc = 0.0\n",
    "\n",
    "t1 = tqdm_notebook(range(n_epochs))\n",
    "\n",
    "for i in t1:\n",
    "    \n",
    "    t2 = tqdm_notebook(range(len(batches)))\n",
    "    for j in t2:\n",
    "        \n",
    "        batch_to_feed = batches[j]\n",
    "        object_labels = objects_label_fake[0:batch_to_feed.size()[0]]\n",
    "        true_part_labels = batches_labels[j]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        part_label_probs = model(batch_to_feed, object_labels)\n",
    "        _,part_labels = torch.max(part_label_probs, dim=1)\n",
    "        \n",
    "        part_labels.squeeze_(-1)\n",
    "        #acc = torch.sum(part_labels==true_part_labels)/float(n_batches*100)\n",
    "\n",
    "        #part_label_probs = part_label_probs.permute(0, 2, 1, 3)\n",
    "        part_label_probs = part_label_probs.squeeze(-1)\n",
    "        loss = loss_fn(part_label_probs, true_part_labels)\n",
    "\n",
    "        total_loss = loss.data[0]\n",
    "        #total_seg_acc = acc.data[0]\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        t2.set_description(f\"Current loss: {total_loss}\")\n",
    "        \n",
    "    t1.set_description(f\"Current epoch: {i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = model(point_cloud, torch.Tensor(convert_label_to_one_hot(np.zeros((3, 100), dtype='int'))).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"checkpoint.pkl\")\n",
    "#model = torch.load(\"checkpoint.pkl\")\n",
    "model.eval();\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "res = []\n",
    "minibatch = 1\n",
    "for i in tqdm_notebook(range(0, n_batches, minibatch)):\n",
    "    \n",
    "    if minibatch == 1:\n",
    "        res += [model(point_cloud[i].unsqueeze(0), object_labels_fake[i].unsqueeze(0)).cpu().detach()]\n",
    "    else:\n",
    "        res += [model(point_cloud[i:i+minibatch], object_labels_fake[i:i+minibatch]).cpu().detach()]\n",
    "        \n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.argmax(res[22][0,:,9,0]))\n",
    "print(labels[22][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
